---
title: "Multiple Uncertainty Revisited"
author: "Carl Boettiger"
date: "11/30/2015"
output: pdf_document
bibliography: citations.bib
---


# Introduction


- Importance of multiple uncertainty

- The surprising sparse history of approaches (at least in optimal fisheries)

- Context of partial observability in other areas, e.g. POMDP (cite Chades papers, Springborn paper)



# Model and Methods

## Model formulation

Our model formulation closely parallels @Sethi2005, which extends
the classic formulation of @Reed1979 to consider implementation and
measurement uncertainty.  Population growth of the stock, $x_t$,
is determined by a stochastic stock $z_t^g$ to the growth function
$G(s_{t-1})$ of the previous year's escaped stock $s_{t-1}$,

$$ x_t = z_t^g G(s_{t-1}) $$

where escapement of a given year is the true stock minus what is harvested, 

$$s_t = x_t - h_t$$

Measured stock, $m$ is determined by a random shock $z_t^m$ to the true stock size $x_t$,

$$ m_t = z_t^m x_t $$

The harvest size is determined by a stochastic stock $z_t^i$ to the
quota $q_t$ set by management policy, or the true stock size
(whichever is smaller)

$$ h_t = \min(x_t, z_t^i q_t) $$

For discount rate $\alpha$ and utility function $U(m_t, q_t(m_t))$,
the fisheries management problem can be written as the choice
(policy) of quotas $\{ q_t \}$ for each year that maximize the
expected total reward:

$$ \max_{\{ q_t\} \geq 0} \mathbb{E} \left[ \sum_0^{\infty} \alpha^t U \left(m_t, q_t(m_t) \right) \right] $$

At each year $t$ the manager measures the stock (with error) $m_t$,
and must then set a quota $q_t$. The optimal solution can thus be
found by dynamic orogramming after defining a Bellman recusion
equation in terms of the observed states $m_t$ and quotas $q_t$:

$$ V_t(m_t) =  \max_{q_t} \left[ U_t(m_t, q_t) + \alpha V_{t+1}(m_t) \right] $$

The trick is simply to define the appropriate utility for each
possible (observed) state $m_t$ and action (quota) $q_t$, and the
appropriate transition probability $P(m_{t+1} | m_t, q_t)$ for each
possible quota $q_t$ and state $m_t$.  In this model, the transition
probability will depend on the growth model and all three sources
of uncertainty.

The expected utility is simpler to construct.  The utility $U_t$
of choosing a quota $q_t$ having measured state $m_t$ is given by
the rewards derived from realizing a harvest $h_t$, integrated over
the probability that a harvest $h_t$ would be realized by a quota
$q_t$ and measurement $m_t$:

$$ U(q_t, m_t)  = \int_x P(x_t | m_t)  \int_h P(h_t | q_t) R(x_t,h_t) dh_t dx_t $$

Computing the probability $P(h|q)$ is straight forward, as it follows
immediately from the distribution from which we choose shocks $h_t
= z_t^i q_t$.  However, the probability $P(x_t | m_t)$ is more
subtle, as we have thus far only defined the inverse relation,
$P(m_t | x_t)$ by defining the shock $z_m^t$ in the expression $m_t
= z_m^t x_t$.  The conditional probability can be reversed with the
help of Bayes Law:

$$P(x_t | m_t ) = \frac{P(m_t | x_t) P(x_t)}{\int P(m_t | x_t) P(x_t) dx_t,}$$

assuming a simple but naive choice of prior belief $P(x_t)$, a
uniform prior. While it would be preferable to define a prior that
was conditional on the previous measurements $m_{\{t-1\}\dots m_0}$,
such a calculation is not ammenable to a stochastic dynamic programming
approach, in which transition probabilities must be defined only
in terms of the current state and would thus have to consider all
possible previous states $m_{t-1}$, as well as current states $m_t$,
in determining the optimal quota $q_t$.  The increased dimension
problem is beyond our scope. The uniform prior neatly sidesteps
this.[^1]  Though @Sethi2005 gloss over this detail in the text, a
closer look at their code (personal comm.) confirms that they have
taken exactly this approach.

[^1]: It is also possible to demonstrate that the qualitative
patterns shown here are not sensitive to the precise choice of the
resulting probability distribution for $P( x_t | m_t)$, see
[results](https://github.com/cboettig/multiple_uncertainty/blob/6f05467a89d355c4aef0a956a614ca03009b92d3/inst/notebook/2015-12-18-different-inverses.md).
We compare these results to what we would find using the respective
inverse probability function (inverse uniform, inverse log-normal),
which compared to the approach discussed above, puts relatively
less weight on stock sizes larger than the observed measurement and
more weight on smaller values.  Note that this only impacts
calculations involving measurement error (not implementation error).


## Numerical implementation




# Results

Figure 1 compares the optimal policies under the assumption of
uniform noise and lognormal noise, using a logistic growth model
with $r = 1$, $K = 100$, on a grid of $x \in [0,200]$ with interval
$\Delta = 0.5$, all following @Sethi2005.  The left panel, uniform
noise, corresponds almost exactly to the modeling assumptions (and
results) of @Sethi2005's Figure 3.  (Note that though @Sethi2005
smooth the resulting policy using a cubic spline to eliminate noise
introduced by the discritization, while here we have plotted the
discrete results directly.  Note that such numerical noise is more
acute in the case of uniform noise distribution, which itself is
not smooth and may be split in-between grid boundaries.)  As in
@Sethi2005, the discounting rate is set at 5%, the reward function
places a fixed price per unit of fish harvested, with no cost to
harvesting effort.  (The appendices explore the robustness of these
results to variation in each of these choices.)


```{r include=FALSE}
knitr::opts_chunk(echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE)
```
```{r libraries, message=FALSE}
library("dplyr")
library("tidyr")
library("ggplot2")
library("multipleuncertainty")
```


```{r compute}
fig3 <- function(noise){  
  grid <- seq(0, 200, by=0.5)
  small     <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = 0.1, sigma_m = 0.1, sigma_i = 0.1, noise_dist = noise)
  growth    <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = 0.5, sigma_m = 0.1, sigma_i = 0.1, noise_dist = noise)
  measure   <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = 0.1, sigma_m = 0.5, sigma_i = 0.1, noise_dist = noise)
  implement <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = 0.1, sigma_m = 0.1, sigma_i = 0.5, noise_dist = noise)
  df <- data.frame(y_grid = grid, small = small, growth = growth, 
                   measure = measure, implement = implement) %>%
    tidyr::gather(scenario, value, -y_grid)
}

df <- 
data.frame(noise = c("uniform", "lognormal")) %>%
  dplyr::group_by(noise) %>%
  dplyr::do(fig3(.$noise))

```

```{r figure1}
df %>% ggplot(aes(x = y_grid, y = value, col = scenario)) + 
    geom_line()  + 
    facet_wrap(~ noise) + 
    xlab("Stock") + 
    ylab("Escapement") + 
    coord_cartesian(xlim = c(0, 150), ylim = c(0,100)) + 
    theme_bw()
```


The most salient comparison in Figure 1 is that, in contrast to the
conclusion reached by @Sethi2005, it is clear that implementation
error




Interpretation of this figure is slightly more challenging due to
the fact that it compares models in which all sources of noise are
present in each case, but in different magnitudes. Observe that at
very large stock estimates, all policies show a deviation from
constant escapement. Though stock sizes significantly larger than
carrying capacity are unlikely in practice, recall that the policy
reflects *measured* stock sizes, not true stock sizes, where this
range is more feasible to imagine (and particularly under the
assumption of uniform measurement error shown here, quite likely
to be observed in the models considered here).

Provided the numerical algorithm is adjusted to treat the case of
zero noise of a given type, we can generate a somewhat cleaner
comparison beween cases with only a single source of noise (or none
at all):


```{r compute}
fig3 <- function(noise){  
  grid <- seq(0, 200, by=0.5)
  small     <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = 0., sigma_m = 0., sigma_i = 0., noise_dist = noise)
  growth    <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = 0.5, sigma_m = 0., sigma_i = 0., noise_dist = noise)
  measure   <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = 0., sigma_m = 0.5, sigma_i = 0., noise_dist = noise)
  implement <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = 0., sigma_m = 0., sigma_i = 0.5, noise_dist = noise)
  df <- data.frame(y_grid = grid, none = small, growth = growth, 
                   measure = measure, implement = implement) %>%
    tidyr::gather(scenario, value, -y_grid)
}

df <- 
data.frame(noise = c("uniform", "lognormal")) %>%
  dplyr::group_by(noise) %>%
  dplyr::do(fig3(.$noise))

```

```{r figure1}
df %>% ggplot(aes(x = y_grid, y = value, col = scenario)) + 
    geom_line()  + 
    facet_wrap(~ noise) + 
    xlab("Stock") + 
    ylab("Escapement") + 
    coord_cartesian(xlim = c(0, 150), ylim = c(0,100)) + 
    theme_bw()
```



# Discussion

Review of general lit


Consistent with Sethi et al, we observe: 

- Small uncertainties lead to only small deviations from classical expectations based on the deterministic model or growth-noise only model.
- Large measurement uncertainty can lead to a significant deviation from "constant escapement"

In contrast to Sethi et al, we find that: 

- These observations are sensitive to way uncertainty is modelled, rather than being generally robust as claimed.

- Large implementation uncertainty can also result in substantial deviations from the the "constant escapement" rule.  

This is most pronounced in more realisitic models of uncertainty, such as log-normally distributed noise, but visible in uniform noise as well.  Small deviations from constant escapement are visible in the implementation error results of @Sethi2005, but are understated.  This contrasts to the @Sethi claim that

> ... implementation sources of uncertainty is high, a constant-escapement policy is qualitatively appropriate since the slopes of these policies beyond the shutdown point are virtually flat.


Substantial deviations from the optimal policy can be found for non-convex growth functions.  In particular, when there is small or negligible cost to harvest, the optimal quota can signficantly exceed the measured stock size, as the true stock size and true harvest can differ substantially.  


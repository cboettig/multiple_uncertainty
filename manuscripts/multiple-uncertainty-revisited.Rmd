---
title: "Multiple Uncertainty Revisited"
author: "Carl Boettiger"
date: "11/30/2015"
output: pdf_document
bibliography: citations.bib
---


# Introduction


- Influence of Reed 1979 in our understanding of management under uncertainty

- Importance of multiple uncertainty

- The surprising sparse history of approaches (at least in optimal fisheries)

- Context of partial observability in other areas, e.g. POMDP (cite Chades papers, Springborn paper)



# Model and Methods

## Model formulation

Our model formulation closely parallels @Sethi2005, which extends
the classic formulation of @Reed1979 to consider implementation and
measurement uncertainty.  Population growth of the stock, $x_t$,
is determined by a stochastic stock $z_t^g$ to the growth function
$G(s_{t-1})$ of the previous year's escaped stock $s_{t-1}$,

$$ x_t = z_t^g G(s_{t-1}) $$

where escapement of a given year is the true stock minus what is harvested, 

$$s_t = x_t - h_t$$

Measured stock, $m$ is determined by a random shock $z_t^m$ to the true stock size $x_t$,

$$ m_t = z_t^m x_t $$

The harvest size is determined by a stochastic stock $z_t^i$ to the
quota $q_t$ set by management policy, or the true stock size
(whichever is smaller)

$$ h_t = \min(x_t, z_t^i q_t) $$

For discount rate $\alpha$ and utility function $U(m_t, q_t(m_t))$,
the fisheries management problem can be written as the choice
(policy) of quotas $\{ q_t \}$ for each year that maximize the
expected total reward:

$$ \max_{\{ q_t\} \geq 0} \mathbb{E} \left[ \sum_0^{\infty} \alpha^t U \left(m_t, q_t(m_t) \right) \right] $$

At each year $t$ the manager measures the stock (with error) $m_t$,
and must then set a quota $q_t$. The optimal solution can thus be
found by dynamic orogramming after defining a Bellman recusion
equation in terms of the observed states $m_t$ and quotas $q_t$:

$$ V_t(m_t) =  \max_{q_t} \left[ U_t(m_t, q_t) + \alpha V_{t+1}(m_t) \right] \label{bellman} $$

The trick is simply to define the appropriate utility for each
possible (observed) state $m_t$ and action (quota) $q_t$, and the
appropriate transition probability $P(m_{t+1} | m_t, q_t)$ for each
possible quota $q_t$ and state $m_t$.  In this model, the transition
probability will depend on the growth model and all three sources
of uncertainty.

The expected utility is simpler to construct.  The utility $U_t$
of choosing a quota $q_t$ having measured state $m_t$ is given by
the rewards derived from realizing a harvest $h_t$, integrated over
the probability that a harvest $h_t$ would be realized by a measurement
$m_t$ and quota $q_t$:

$$ U(m_t, q_t)  = \int_x P(x_t | m_t)  \int_h P(h_t | q_t) R(x_t,h_t) dh_t dx_t \label{utility} $$

Computing the probability $P(h|q)$ is straight forward, as it follows
immediately from the distribution from which we choose shocks $h_t
= z_t^i q_t$.  However, the probability $P(x_t | m_t)$ is more
subtle[^1], as we have thus far only defined the inverse relation,
$P(m_t | x_t)$ by defining the shock $z_m^t$ in the expression $m_t
= z_m^t x_t$.  The conditional probability can be reversed with the
help of Bayes Law:

$$P(x_t | m_t ) = \frac{P(m_t | x_t) P(x_t)}{\int P(m_t | x_t) P(x_t) dx_t,}$$

assuming a simple but naive choice of prior belief $P(x_t)$, a
uniform prior. While it would be preferable to define a prior that
was conditional on the previous measurements $m_{\{t-1\}\dots m_0}$,
this would forefit the Markovian assumption need to make the problem
amenable to solution. Such a calculation is not ammenable to a stochastic dynamic programming
approach, in which transition probabilities must be defined only
in terms of the current state and would thus have to consider all
possible previous states $m_{t-1}$, as well as current states $m_t$,
in determining the optimal quota $q_t$.  The increased dimension
problem is beyond our scope. The uniform prior neatly sidesteps
this.[^2]  Though @Sethi2005 gloss over any detail about how $P(x_t | m_t)$
is constructed, confirms that they have
taken exactly this approach.

[^1]: Introducing measurement uncertainty into Markov Decision Processes
is the focus of Partially Observed Markov Decision Processes (POMDP) research,
an active area in artificial intelligence community. Solutions do not use dynamic
programming algorithm, relying instead on a variety of approximation algorithms
which the mathematical biology community would recognize more as Expectation-Maximization (EM)
algorithms for Hidden Markov Models.  These models permit active or online learning
about the process, rather than the single optimal policy functions considered here.
Their analysis is beyond the scope of this paper.  

[^2]: It is also possible to demonstrate that the qualitative
patterns shown here are not sensitive to the precise choice of the
resulting probability distribution for $P( x_t | m_t)$, see
[results](https://github.com/cboettig/multiple_uncertainty/blob/6f05467a89d355c4aef0a956a614ca03009b92d3/inst/notebook/2015-12-18-different-inverses.md).
We compare these results to what we would find using the respective
inverse probability function (inverse uniform, inverse log-normal),
which compared to the approach discussed above, puts relatively
less weight on stock sizes larger than the observed measurement and
more weight on smaller values.  Note that this only impacts
calculations involving measurement error (not implementation error).


## Numerical implementation


We solve the optimization problem using Stochastic Dynamic Programming, by first
discritizing the problem described above and then determining the resluting utility
matrix, $\mathcal{U}_{mq}$ and transition probability between measured states for
each possible choice of quota, $\mathcal{T}_{m_t, m_{t+1}, q_t}$.  Given this matrix
and tensor, the optimization can be solved through the standard policy iteration algorithm.
We provide complete R code and Matlab/Octave code implementations for readers interested
in the details or in running the algorithm and exploring on their own.


We discritize the state space 
(stock $x_t$, observed stock $m_t$, harvest $h_t$, quota $q_t$) onto
identical uniform grids between values between 0 and 200 at 0.5 unit step size.
(In general each dimension could have a different discritization; for instance,
allowing the measured stock sizes and/or chosen quotas to limited to a coarser
grid than the true dynamics, which could reflect real-world limitations and
not merely numerical necessity.)

The Supplemental material compares our results across a range of grid
lengths and step sizes to confirm this choice is sufficient to minimize
numerical errors introduced by the discritization.  

Note that @Sethi2005 perform a similar discritization but present only cubic-spline interpolations
of the resulting policies. While this can supress numerical artifacts of the
discritization, it can also merely blurr them or introduce additional artifacts.
We present the policies as determined by discrete optimization without smoothing
by splines, making interpretation more straight-forward.


In the discrete problem, the Utility function $U(m_t, q_t)$ can be written as a
matrix $\mathcal{U}_{mq}$, of size length(quota grid) by length(measurement grid).  To do so, we 
begin by defining the matrix $\mathcal{R}_{xh}$ for the reward function $R(x_t, h_t)$ for harvest
of $h_t$ at stock size $x_t$ for each of their respective grid point values. 
We can then define a matrix $\mathcal{P}_{hq}$ as the probability of a harvest $h_t$ given a 
quota set at $q_t$ from the assumed probability distribution $P(h_t | q_t)$. 
Likewise given the probability of a true stock size of $x_t$ given a measurement of $m_t$, 
$P(x_t | m_t)$ we define the probability matrix $\mathcal{P}_{xm}$.  Then the matrix products 

$$\mathcal{U}_{mq} = \mathcal{P}_{xm} \mathcal{R}_{xh} \mathcal{P}_{hq}$$ 

are the discrete equivalent of integrating over $h$ and $x$ in Eqn~\eqref{utility},
giving us the utility matrix $\mathcal{U}_{mq}$.  

The transition probability tensor is likewise defined in the space of the
manager (measured stock, quota), which must also be computed from the 
true state of the system (stock, harvest).  

# Results

Figure 1 compares the optimal policies under the assumption of
uniform noise and lognormal noise, using a logistic growth model
with $r = 1$, $K = 100$, on a grid of $x \in [0,200]$ with interval
$\Delta = 0.5$, all following @Sethi2005.  The left panel, uniform
noise, corresponds almost exactly to the modeling assumptions (and
results) of @Sethi2005's Figure 3.  (Note that the impact of 
discritization is more
acute in the case of uniform noise distribution, which itself is
not smooth and may be split in-between grid boundaries.)  As in
@Sethi2005, the discounting rate is set at 5%, the reward function
places a fixed price per unit of fish harvested, with no cost to
harvesting effort.  (The appendices explore the robustness of these
results to variation in each of these choices.)


```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE)
```


```{r libraries, message=FALSE}
library("dplyr")
library("tidyr")
library("ggplot2")
library("multipleuncertainty")
```


```{r compute}
fig3 <- function(noise){  
  grid <- seq(0, 200, by=0.5)
  
  ## Scale noise comparably for log-normal vs uniform
  if(noise == "lognormal"){
    lo <- 0.0577 # 0.1 / sqrt(3)
    hi <- 0.2887 # 0.5 / sqrt(3)
  } else {
    lo <- 0.1
    hi <- 0.5
  }
  small     <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = lo, sigma_m = lo, sigma_i = lo, noise_dist = noise)
  growth    <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = hi, sigma_m = lo, sigma_i = lo, noise_dist = noise)
  measure   <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = lo, sigma_m = hi, sigma_i = lo, noise_dist = noise)
  implement <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = lo, sigma_m = lo, sigma_i = hi, noise_dist = noise)
  large     <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = hi, sigma_m = hi, sigma_i = hi, noise_dist = noise)
  df <- data.frame(y_grid = grid, small = small, growth = growth, 
                   measure = measure, implement = implement, large = large) %>%
    tidyr::gather(scenario, value, -y_grid)
}

df <- 
data.frame(noise = c("uniform", "lognormal")) %>%
  dplyr::group_by(noise) %>%
  dplyr::do(fig3(.$noise))

```

```{r figure1, dependson="compute"}
df %>% ggplot(aes(x = y_grid, y = value, col = scenario)) + 
    geom_line()  + 
    facet_wrap(~ noise) + 
    xlab("Stock") + 
    ylab("Escapement") + 
    coord_cartesian(xlim = c(0, 150), ylim = c(0,100)) + 
    theme_bw()
```


The most salient result seen in Figure 1 is that both implementation
error and measurement error can result in substantial deviations
from the classic "Constant Escapment" result of @Reed1979.  Such a result 
also stands in contrast to the conclusions of @Sethi2005, which emphasize
that only measurement error can be responsible for significant deviations.
@Sethi2005 consider only the case of uniform noise, and examine the optimal
policy only for measured stock sizes less than or equal to carrying capacity
(despite the fact that under the model assumption of large and uniformly
distributed measurement noise, values greater than carrying capacity 
will be not unfrequently realized even while true stocks are likely to remain
below that value.)







Interpretation of this figure is slightly more challenging due to
the fact that it compares models in which all sources of noise are
present in each case, but in different magnitudes. Observe that at
very large stock estimates, all policies show a deviation from
constant escapement (while @Reed1979 proves that the optimal solution for
stochastic growth without other sources of uncertainty is a constant escapement
policy even for stock sizes exceeding th ecarrying capacity). The deviations 
seen here are not numerical artifact, but due to the precence of small but
non-zero measurement error, and can be understood as follows:

Though stock sizes significantly larger than
carrying capacity are unlikely in practice, recall that the policy
reflects *measured* stock sizes, not true stock sizes, where this
range is more feasible to imagine (and particularly under the
assumption of uniform measurement error shown here, quite likely
to be observed in the models considered here).

Provided the numerical algorithm is adjusted to treat the case of
zero noise of a given type, we can generate a somewhat cleaner
comparison beween cases with only a single source of noise (or none
at all), Figure 2.  Observe that the deterministic and growth-only
solutions now recover the constant-escapement rule exactly.


```{r compute2}
fig3 <- function(noise){  
  grid <- seq(0, 200, by=0.5)
  
  ## Scale noise comparably for log-normal vs uniform
  if(noise == "lognormal"){
    hi <- 0.2887 # 0.5 / sqrt(3)
  } else {
    hi <- 0.5
  }
  lo <- 0.0
  
  small     <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = lo, sigma_m = lo, sigma_i = lo, noise_dist = noise)
  growth    <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = hi, sigma_m = lo, sigma_i = lo, noise_dist = noise)
  measure   <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = lo, sigma_m = hi, sigma_i = lo, noise_dist = noise)
  implement <- multiple_uncertainty(f = logistic, x_grid = grid, sigma_g = lo, sigma_m = lo, sigma_i = hi, noise_dist = noise)
  df <- data.frame(y_grid = grid, none = small, growth = growth, 
                   measure = measure, implement = implement) %>%
    tidyr::gather(scenario, value, -y_grid)
}

df <- 
data.frame(noise = c("uniform", "lognormal")) %>%
  dplyr::group_by(noise) %>%
  dplyr::do(fig3(.$noise))

```

```{r figure2}
df %>% ggplot(aes(x = y_grid, y = value, col = scenario)) + 
    geom_line()  + 
    facet_wrap(~ noise) + 
    xlab("Stock") + 
    ylab("Escapement") + 
    coord_cartesian(xlim = c(0, 150), ylim = c(0,100)) + 
    theme_bw()
```



# Discussion

Review of general lit


Consistent with Sethi et al, we observe: 

- Small uncertainties lead to only small deviations from classical expectations based on the deterministic model or growth-noise only model.
- Large measurement uncertainty can lead to a significant deviation from "constant escapement"

In contrast to Sethi et al, we find that: 

- These observations are sensitive to way uncertainty is modelled, rather than being generally robust as claimed.

- Large implementation uncertainty can also result in substantial deviations from the the "constant escapement" rule.  

This is most pronounced in more realisitic models of uncertainty, such as log-normally distributed noise, but visible in uniform noise as well.  Small deviations from constant escapement are visible in the implementation error results of @Sethi2005, but are understated.  This contrasts to the @Sethi claim that

> ... implementation sources of uncertainty is high, a constant-escapement policy is qualitatively appropriate since the slopes of these policies beyond the shutdown point are virtually flat.


Substantial deviations from the optimal policy can be found for non-convex growth functions.  In particular, when there is small or negligible cost to harvest, the optimal quota can signficantly exceed the measured stock size, as the true stock size and true harvest can differ substantially.  

